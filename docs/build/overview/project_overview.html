

<!DOCTYPE html>
<html class="writer-html5" lang="en" data-content_root="../">
<head>
  <meta charset="utf-8" /><meta name="viewport" content="width=device-width, initial-scale=1" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Overview &mdash; Reinforcement Learning for Ising Model  documentation</title>
      <link rel="stylesheet" type="text/css" href="../_static/pygments.css?v=b86133f3" />
      <link rel="stylesheet" type="text/css" href="../_static/css/theme.css?v=e59714d7" />
      <link rel="stylesheet" type="text/css" href="../_static/css/custom.css" />

  
      <script src="../_static/jquery.js?v=5d32c60e"></script>
      <script src="../_static/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
      <script src="../_static/documentation_options.js?v=5929fcd5"></script>
      <script src="../_static/doctools.js?v=9bcbadda"></script>
      <script src="../_static/sphinx_highlight.js?v=dc90522c"></script>
      <script crossorigin="anonymous" integrity="sha256-Ae2Vz/4ePdIu6ZyI/5ZGsYnb+m0JlOmKPjt6XZ9JJkA=" src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >

          
          
          <a href="../index.html" class="icon icon-home">
            Reinforcement Learning for Ising Model
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" aria-label="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Introduction</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="key_concepts.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="motivation.html">Motivation</a></li>
<li class="toctree-l1"><a class="reference internal" href="content.html">Content</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Datasets</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../datasets/classification.html">Classification of Ising Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/spin_glass.html">Spin Glass Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/spin_ice.html">Spin-Ice Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/ferromagnetic.html">Ferromagnetic Dataset</a></li>
<li class="toctree-l1"><a class="reference internal" href="../datasets/anti_ferromagnetic.html">Anti-Ferromagnetic Dataset</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Baseline Solvers</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../solvers/gurobi.html">Gurobi Solver</a></li>
<li class="toctree-l1"><a class="reference internal" href="../solvers/cplex.html">IBM ILOG CPLEX Solver</a></li>
<li class="toctree-l1"><a class="reference internal" href="../solvers/copt.html">COPT Solver</a></li>
<li class="toctree-l1"><a class="reference internal" href="../solvers/scip.html">SCIP Solver</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RL Algorithms</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../methods/s2v.html">S2V-DQN Algorithm</a></li>
<li class="toctree-l1"><a class="reference internal" href="../methods/vca.html">Variational Neural Annealing (VCA)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../methods/mcpg.html">Monte Carlo Policy Gradient with Local Search (MCPG)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../methods/reinforce.html">REINFORCE Algorithm</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">Benchmarks</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../benchmark/results.html">Benchmark Results</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">RL4Ising Competition 2025</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../competition/overview.html">Overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../competition/rl4maxcut.html">Task 1: RL4MaxCut</a></li>
<li class="toctree-l1"><a class="reference internal" href="../competition/rl4ising.html">Task 2: RL4Ising</a></li>
</ul>
<p class="caption" role="heading"><span class="caption-text">References</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../references/dataset_references.html">Dataset References</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../index.html">Reinforcement Learning for Ising Model</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../index.html" class="icon icon-home" aria-label="Home"></a></li>
      <li class="breadcrumb-item active">Overview</li>
      <li class="wy-breadcrumbs-aside">
              <a href="https://github.com/Open-Finance-Lab/RL4Ising/blob/main/docs/source/overview/project_overview.rst" class="fa fa-github"> Edit on GitHub</a>
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <section id="overview">
<h1>Overview<a class="headerlink" href="#overview" title="Link to this heading"></a></h1>
<nav class="contents local" id="table-of-contents">
<p class="topic-title">Table of Contents</p>
<ul class="simple">
<li><p><a class="reference internal" href="#motivation" id="id1">Motivation</a></p>
<ul>
<li><p><a class="reference internal" href="#significance-of-ising-model" id="id2">Significance of Ising Model</a></p></li>
<li><p><a class="reference internal" href="#introduction-to-reinforcement-learning" id="id3">Introduction to Reinforcement Learning</a></p></li>
<li><p><a class="reference internal" href="#why-reinforcement-learning" id="id4">Why Reinforcement Learning</a></p></li>
<li><p><a class="reference internal" href="#rl-applications-towards-ising-model-solutions" id="id5">RL Applications Towards Ising Model Solutions</a></p></li>
</ul>
</li>
<li><p><a class="reference internal" href="#goals" id="id6">Goals</a></p>
<ul>
<li><p><a class="reference internal" href="#dataset" id="id7">Dataset</a></p></li>
<li><p><a class="reference internal" href="#benchmark" id="id8">Benchmark</a></p></li>
<li><p><a class="reference internal" href="#tutorials" id="id9">Tutorials</a></p></li>
</ul>
</li>
</ul>
</nav>
<section id="motivation">
<h2><a class="toc-backref" href="#id1" role="doc-backlink">Motivation</a><a class="headerlink" href="#motivation" title="Link to this heading"></a></h2>
<p>The Ising model has been a fundamental problem in statistical physics for over a century, providing insight into phase transitions, magnetism, and critical phenomena. Our objective is to
leverage the advances in RL to offer a more effective approach to finding solutions of the Ising model.</p>
<p>Through this project, we systematically demonstrate the advantages of different model architectures and learning paradigms when applied to the Ising model. By doing so, we strive to
showcase the strength of RL applied to this problem.</p>
<p>Chiefly, our goal is to illustrate that RL approaches can surpass traditional methods in both performance and scalability. Moreover, we believe RL-based methods have the potential to
advance what has been a long-standing challenge in physics and related fields.</p>
<section id="significance-of-ising-model">
<h3><a class="toc-backref" href="#id2" role="doc-backlink">Significance of Ising Model</a><a class="headerlink" href="#significance-of-ising-model" title="Link to this heading"></a></h3>
<p>The Ising model, a mathematical model in statistical mechanics, has been a cornerstone in modeling a variety of physics-based systems. The model involves a lattice of spins, each of which
are in one of two states, with interactions dependent on neighboring spins. Finding solutions to the Ising model is critical in effectively simulating and understanding physical
phenomena. Further, the Ising model problem can be abstracted to various other fields, such as computer science, social science, and biology. Developing an efficient solver to this problem
would enable advancements in fields broader than solely physics.</p>
<p>Traditionally, the Ising model has been approached with techniques like Monte Carlo simulation. While this method provides high-quality results, it can be computationally expensive,
especially in high-dimensional systems. Moreover, obtaining high-quality solutions in complex systems is difficult due to the nonconvex, large solution space. Recently, reinforcement
learning paradigms have been able to efficiently learn NP-hard problems such as the Ising model, and can find high-quality solutions.</p>
</section>
<section id="introduction-to-reinforcement-learning">
<h3><a class="toc-backref" href="#id3" role="doc-backlink">Introduction to Reinforcement Learning</a><a class="headerlink" href="#introduction-to-reinforcement-learning" title="Link to this heading"></a></h3>
<p>Reinforcement Learning is a type of machine learning where an agent learns to make decisions by interacting with an environment and receiving feedback in the form of rewards and penalties.
Through repetitive trials, the agent learns to perform actions that maximize a long-term reward. This type of feedback system can be applied to the Ising model where rewards can be given
as the agent arranges the spins more closely to a ground state configuration.</p>
</section>
<section id="why-reinforcement-learning">
<h3><a class="toc-backref" href="#id4" role="doc-backlink">Why Reinforcement Learning</a><a class="headerlink" href="#why-reinforcement-learning" title="Link to this heading"></a></h3>
<p>…</p>
</section>
<section id="rl-applications-towards-ising-model-solutions">
<h3><a class="toc-backref" href="#id5" role="doc-backlink">RL Applications Towards Ising Model Solutions</a><a class="headerlink" href="#rl-applications-towards-ising-model-solutions" title="Link to this heading"></a></h3>
<p>We will now highlight some of the benefits of RL, and how they apply to the Ising model.</p>
<ol class="arabic simple">
<li><p><strong>Efficient Exploration of Solution space:</strong> One of the largest constraints when solving the Ising model is the vast number of configurations. Traditional methods may use techniques
such as random sampling to find potential solutions to the problem. This becomes extremely inefficient for large systems and encourages the use of alternative solvers that employ
stochastic methods of finding solutions. RL, however, can guide the exploration of the spin configurations more effectively. By training an agent to explore the solution space, it
can learn the most promising regions of the graph to focus on, thus speeding up convergence to high-quality solutions.</p></li>
<li><p><strong>Improving Quality of Solutions:</strong> By using RL to optimize the configurations of spins, the agent can minimize the energy of a system more efficiently than traditional methods. This
translates to solutions being found that are closer to the optimal solution. This improvement is beneficial in large systems or systems with complex interactions.</p></li>
<li><p><strong>Real-time Adaptation:</strong> Another advantage of RL is its ability to adapt in real-time. In the context of the Ising model, this mean that the RL agent can adjust its strategy as it explores the environment.</p></li>
</ol>
<p>The integration of RL as a solver for the Ising model holds great promise for improving efficiency and accuracy. In particular, by leveraging RL’s capabilities for dynamic adaptation,
efficient exploration, and quality optimization, an RL-enabled solver can outperform traditional methods.</p>
</section>
</section>
<section id="goals">
<h2><a class="toc-backref" href="#id6" role="doc-backlink">Goals</a><a class="headerlink" href="#goals" title="Link to this heading"></a></h2>
<section id="dataset">
<h3><a class="toc-backref" href="#id7" role="doc-backlink">Dataset</a><a class="headerlink" href="#dataset" title="Link to this heading"></a></h3>
<p>…</p>
</section>
<section id="benchmark">
<h3><a class="toc-backref" href="#id8" role="doc-backlink">Benchmark</a><a class="headerlink" href="#benchmark" title="Link to this heading"></a></h3>
<p>…</p>
</section>
<section id="tutorials">
<h3><a class="toc-backref" href="#id9" role="doc-backlink">Tutorials</a><a class="headerlink" href="#tutorials" title="Link to this heading"></a></h3>
<p>…</p>
<p>The primary goal of this project is to create a comprehensive dataset and benchmark for solving the Ising model. This dataset will serve as a resource for researchers and developers aiming
to compare and evaluate a range of solvers and methodologies on the Ising model. By providing a consistent, reproducible framework, the project seeks to facilitate comparisons for the
development of new techniques.</p>
<ol class="arabic simple">
<li><p><strong>Constructing a Robust Dataset:</strong> The dataset will consist of a variety of Ising model configurations across different system sizes, lattice types, and Ising model types. These diverse
datasets will enable the testing of solvers spanning real-world scenarios. This ensures that each method can be evaluated on instances that range from easy to hard to fully capture
the solver’s ability. By including various boundary conditions, spin interactions, and lattice structures, the dataset will ensure that all important aspects of the Ising model are
represented.</p></li>
<li><p><strong>Benchmarking Solvers:</strong> A key objective is to establish benchmarks for comparing the performance of different solvers for the Ising model. These benchmarks will provide information
on both the efficiency and quality of the solver. We will compare the strengths and weaknesses of each solver across different conditions and help researchers identify the best methods.</p></li>
<li><p><strong>Reproducibility:</strong> To encourage the continued evolution of solvers for this problem, all data and experiments will be made publicly available, allowing other researchers to reproduce
the findings. This reproducibility is crucial for validating new methods and ensuring advances made are based on verifiable results. By providing detailed codebases, this project aims
to contribute to the broader scientific community and accelerate the pace of research in statistical mechanics, machine learning, and optimization.</p></li>
</ol>
</section>
</section>
</section>


           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2025, Reinforcement Learning for Ising Model.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>