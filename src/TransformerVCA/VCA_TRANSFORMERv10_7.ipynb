{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8bd8323",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfcbfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "\n",
    "class SimpleConfig:\n",
    "    def __init__(self, graph_path: str = \"\"):\n",
    "        \"\"\"\n",
    "        Initialize a configuration object for graph-based or physics-inspired models.\n",
    "        If a valid graph file path is provided, the graph will be loaded from that file.\n",
    "        Otherwise, a random symmetric coupling matrix (representing a random graph)\n",
    "        will be generated.\n",
    "\n",
    "        Parameters:\n",
    "            graph_path (str): Optional path to a text file defining the graph structure.\n",
    "        \"\"\"\n",
    "\n",
    "        if graph_path and os.path.exists(graph_path):\n",
    "            print(\"using\", graph_path)\n",
    "            # Load the coupling matrix (Jz) and edge list (graph_list) from a file\n",
    "            self.Jz, self.graph_list = self.from_txt_load_graph(graph_path)\n",
    "            # Derive the number of nodes based on the loaded edge list\n",
    "            self.num_nodes = self.obtain_num_nodes(self.graph_list)\n",
    "        else:\n",
    "            print(\"random graph\")\n",
    "            # If no file is given or file not found, create a random graph\n",
    "            self.num_nodes = 20  # Default number of nodes\n",
    "            # Generate a random symmetric matrix with entries ~ N(0, 1/sqrt(N))\n",
    "            # This scaling helps maintain numerical stability as N increases\n",
    "            self.Jz = np.random.normal(0, 1/np.sqrt(self.num_nodes), size=(self.num_nodes, self.num_nodes))\n",
    "            # Make sure the matrix is symmetric, since the graph is undirected\n",
    "            self.Jz = (self.Jz + self.Jz.T) / 2\n",
    "            # Empty list — no explicit edge data since it’s random\n",
    "            self.graph_list = []\n",
    "\n",
    "        # Random seed for reproducibility\n",
    "        self.seed = 1\n",
    "\n",
    "        # Transformer model hyperparameters (for possible machine learning applications)\n",
    "        self.d_model = 16       # Hidden dimension size of the model\n",
    "        self.num_heads = 1      # Number of attention heads in the transformer\n",
    "        self.num_layers = 1     # Number of transformer layers\n",
    "        self.dff = 64           # Dimension of the feedforward network inside the transformer\n",
    "\n",
    "        # Simulation or training parameters\n",
    "        self.numsamples = 64            # Number of Monte Carlo or training samples\n",
    "        self.lr = 5 * (1e-4)            # Learning rate for optimizer\n",
    "        self.T0 = 1.0                   # Initial temperature (often used in annealing)\n",
    "        self.Bx0 = 0                    # Initial transverse field (for quantum models)\n",
    "        self.num_warmup_steps = 100     # Steps before starting annealing/sampling\n",
    "        self.num_annealing_steps = 20   # Number of annealing (temperature reduction) steps\n",
    "        self.num_equilibrium_steps = 10 # Steps for reaching equilibrium per temperature\n",
    "\n",
    "    def from_txt_load_graph(self, graph_path: str):\n",
    "        \"\"\"\n",
    "        Load a graph structure from a text file.\n",
    "\n",
    "        Expected file format:\n",
    "            Line 1: <num_spins> <num_couplings>\n",
    "            Following lines: <spin1> <spin2> <weight>\n",
    "            - Spins are 1-indexed in the file and will be converted to 0-indexed internally.\n",
    "            - Each line represents an undirected weighted edge between two spins/nodes.\n",
    "\n",
    "        Returns:\n",
    "            Jz (np.ndarray): A symmetric NxN coupling (adjacency) matrix.\n",
    "            graph_list (list): A list of tuples (node1, node2, weight).\n",
    "        \"\"\"\n",
    "        with open(graph_path, \"r\") as file:\n",
    "            # First line defines the number of spins (nodes) and couplings (edges)\n",
    "            spins, couplings = file.readline().split(\" \")\n",
    "            N = int(spins)\n",
    "            # Initialize an empty NxN matrix for edge weights\n",
    "            Jz = np.zeros((N, N), dtype=np.float64)\n",
    "            graph_list = []\n",
    "\n",
    "            # Read edge data line by line\n",
    "            line = file.readline()\n",
    "            while line and line.strip():\n",
    "                spin1, spin2, weight = line.split(\" \")\n",
    "                # Convert to 0-based indices for internal storage\n",
    "                idx1, idx2 = int(spin1) - 1, int(spin2) - 1\n",
    "                weight = float(weight)\n",
    "                # Store the weight symmetrically since the graph is undirected\n",
    "                Jz[idx1, idx2] = weight\n",
    "                Jz[idx2, idx1] = weight\n",
    "                # Append edge information to the list\n",
    "                graph_list.append((idx1, idx2, weight))\n",
    "                # Read next line\n",
    "                line = file.readline()\n",
    "\n",
    "        return Jz, graph_list\n",
    "\n",
    "    def obtain_num_nodes(self, graph_list):\n",
    "        \"\"\"\n",
    "        Determine the number of nodes in a graph based on its edge list.\n",
    "\n",
    "        Parameters:\n",
    "            graph_list (list): List of edges, each represented as (node1, node2, weight).\n",
    "\n",
    "        Returns:\n",
    "            int: The total number of distinct nodes.\n",
    "        \"\"\"\n",
    "        if not graph_list:\n",
    "            return 0\n",
    "        # Find the maximum node index appearing in any edge, then add 1\n",
    "        # because nodes are zero-indexed internally\n",
    "        return max([max(n0, n1) for n0, n1, w in graph_list]) + 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bb4545",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2bf58c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import math\n",
    "\n",
    "class TransformerWavefunction(nn.Module):\n",
    "    def __init__(self, config):\n",
    "        \"\"\"\n",
    "        A Transformer-based autoregressive wavefunction model.\n",
    "        Designed to represent probability distributions over spin configurations,\n",
    "        similar to models used in quantum Monte Carlo or generative physical systems.\n",
    "\n",
    "        Args:\n",
    "            config: A configuration object (e.g., SimpleConfig) containing model hyperparameters.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.N = config.num_nodes        # Number of spins/nodes in the system\n",
    "        self.d_model = config.d_model    # Hidden dimension of the Transformer\n",
    "        self.num_heads = config.num_heads\n",
    "        self.num_layers = config.num_layers\n",
    "        self.dff = config.dff            # Feedforward layer size\n",
    "\n",
    "        # ===== Embedding layer setup =====\n",
    "        # We use an embedding for 3 tokens:\n",
    "        #   0 -> spin down, 1 -> spin up, 2 -> <sos> (start-of-sequence token)\n",
    "        self.embedding = nn.Embedding(3, self.d_model)\n",
    "\n",
    "        # Positional embeddings (added to token embeddings)\n",
    "        # Randomly initialized and scaled by sqrt(d_model) for stability\n",
    "        self.pos_embedding = nn.Parameter(\n",
    "            torch.randn(1, self.N + 1, self.d_model) / math.sqrt(self.d_model)\n",
    "        )\n",
    "\n",
    "        # Layer normalization for stabilizing embedding outputs\n",
    "        self.emb_ln = nn.LayerNorm(self.d_model)\n",
    "\n",
    "        # ===== Transformer Encoder =====\n",
    "        # Using a pre-LayerNorm TransformerEncoderLayer (norm_first=True)\n",
    "        # Pre-LN is more stable for deep or autoregressive settings.\n",
    "        decoder_layer = nn.TransformerEncoderLayer(\n",
    "            d_model=self.d_model,\n",
    "            nhead=self.num_heads,\n",
    "            dim_feedforward=self.dff,\n",
    "            dropout=0.0,\n",
    "            activation=\"relu\",\n",
    "            batch_first=True,\n",
    "            norm_first=True  # Use pre-LN (set to False or remove if unsupported)\n",
    "        )\n",
    "        self.transformer = nn.TransformerEncoder(decoder_layer, num_layers=self.num_layers)\n",
    "\n",
    "        # Final linear layer to map Transformer outputs to logits over spin values (0/1)\n",
    "        self.fc_out = nn.Linear(self.d_model, 2)\n",
    "\n",
    "        # Output temperature scaling (helps prevent overly sharp probability distributions)\n",
    "        # This can also be defined as a learnable parameter if needed.\n",
    "        self.out_tau = 1.2  # Recommended range: 1.0–1.5\n",
    "\n",
    "    @staticmethod\n",
    "    def _causal_mask(L, device):\n",
    "        \"\"\"\n",
    "        Create a causal attention mask of size (L, L).\n",
    "        Entries above the diagonal are True (masked out),\n",
    "        ensuring that each token only attends to past tokens.\n",
    "        \"\"\"\n",
    "        return torch.triu(torch.ones(L, L, device=device, dtype=torch.bool), diagonal=1)\n",
    "\n",
    "    def forward(self, tokens, use_out_tau=True):\n",
    "        \"\"\"\n",
    "        Forward pass of the Transformer.\n",
    "\n",
    "        Args:\n",
    "            tokens (torch.LongTensor): Input sequence of shape (B, T), where\n",
    "                T <= N+1. The first token may be the <sos> token (value=2).\n",
    "            use_out_tau (bool): Whether to apply output temperature scaling.\n",
    "\n",
    "        Returns:\n",
    "            probs (torch.FloatTensor): Shape (B, T, 2), probabilities for spin values (0/1)\n",
    "        \"\"\"\n",
    "        # Token embeddings + positional embeddings\n",
    "        x = self.embedding(tokens) + self.pos_embedding[:, :tokens.size(1), :]\n",
    "        x = self.emb_ln(x)\n",
    "\n",
    "        # Apply causal attention mask to prevent information leakage from future steps\n",
    "        mask = self._causal_mask(tokens.size(1), tokens.device)\n",
    "\n",
    "        # Pass through Transformer encoder\n",
    "        h = self.transformer(x, mask=mask)\n",
    "\n",
    "        # Map final hidden states to logits for 2 spin classes\n",
    "        logits = self.fc_out(h)\n",
    "\n",
    "        # Apply temperature scaling to logits for smoother probabilities\n",
    "        if use_out_tau and self.out_tau != 1.0:\n",
    "            logits = logits / self.out_tau\n",
    "\n",
    "        # Convert logits to probabilities\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        return probs  # Shape: (B, T, 2)\n",
    "\n",
    "    def log_probability(self, spins):\n",
    "        \"\"\"\n",
    "        Compute the log-probability of given spin configurations.\n",
    "\n",
    "        Args:\n",
    "            spins (torch.LongTensor): Tensor of shape (B, N), each element ∈ {0,1}\n",
    "\n",
    "        Returns:\n",
    "            logp (torch.FloatTensor): Log-probabilities for each configuration (B,)\n",
    "        \"\"\"\n",
    "        B = spins.size(0)\n",
    "        device = spins.device\n",
    "\n",
    "        # Prepend <sos> token (start-of-sequence)\n",
    "        sos = torch.full((B, 1), 2, dtype=torch.long, device=device)\n",
    "        tokens = torch.cat([sos, spins], dim=1)  # Shape: (B, N+1)\n",
    "\n",
    "        # Forward pass through the model (excluding last prediction)\n",
    "        probs = self.forward(tokens)[:, :-1, :]  # (B, N, 2)\n",
    "\n",
    "        # Create one-hot encoding for actual spins and select their probabilities\n",
    "        one_hot = F.one_hot(spins, num_classes=2).float()\n",
    "        sel = (probs * one_hot).sum(dim=-1)  # Select the probability for each true spin value\n",
    "\n",
    "        # Compute total log-probability\n",
    "        logp = torch.log(sel.clamp_min(1e-12)).sum(dim=-1)  # (B,)\n",
    "        return logp\n",
    "\n",
    "    @torch.no_grad()\n",
    "    def sample(self, numsamples, tau_sample=1.0, epsilon=0.0):\n",
    "        \"\"\"\n",
    "        Autoregressive sampling of spin configurations.\n",
    "\n",
    "        Args:\n",
    "            numsamples (int): Number of samples to generate.\n",
    "            tau_sample (float): Sampling temperature; <1.0 makes samples sharper, >1.0 softer.\n",
    "            epsilon (float): Epsilon-exploration rate; mixes in uniform noise to avoid collapse.\n",
    "\n",
    "        Returns:\n",
    "            spins (torch.LongTensor): Sampled spin configurations of shape (B, N)\n",
    "            logp (torch.FloatTensor): Log-probabilities of each sample (B,)\n",
    "        \"\"\"\n",
    "        device = next(self.parameters()).device\n",
    "        B = numsamples\n",
    "\n",
    "        # Start each sequence with <sos> token\n",
    "        tokens = torch.full((B, 1), 2, dtype=torch.long, device=device)\n",
    "        logp_parts = []\n",
    "\n",
    "        # Sequentially generate spins one by one\n",
    "        for n in range(self.N):\n",
    "            # Compute probability distribution for the next spin\n",
    "            probs = self.forward(tokens, use_out_tau=True)[:, -1, :]  # (B, 2)\n",
    "\n",
    "            # Apply temperature scaling to sampling probabilities\n",
    "            if tau_sample != 1.0:\n",
    "                probs = F.softmax((probs.clamp_min(1e-20)).log() / tau_sample, dim=-1)\n",
    "\n",
    "            # Epsilon-exploration: mix in a uniform distribution to encourage diversity\n",
    "            if epsilon > 0.0:\n",
    "                probs = (1.0 - epsilon) * probs + epsilon * 0.5\n",
    "\n",
    "            # Sample next spin from categorical distribution\n",
    "            dist = torch.distributions.Categorical(probs)\n",
    "            s = dist.sample()  # (B,)\n",
    "            tokens = torch.cat([tokens, s[:, None]], dim=1)\n",
    "\n",
    "            # Record log-probabilities\n",
    "            logp_parts.append(dist.log_prob(s))\n",
    "\n",
    "        # Remove the <sos> token from the final sequence\n",
    "        spins = tokens[:, 1:]\n",
    "        logp = torch.stack(logp_parts, dim=1).sum(dim=1)\n",
    "        return spins, logp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "878c7cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, numpy as np, time\n",
    "import torch.nn.functional as F\n",
    "import random\n",
    "\n",
    "def local_energy_SK(Jz, samples):\n",
    "    # samples: (B, N) in {0,1} -> {-1,+1}\n",
    "    spins = (2 * samples.cpu().numpy()) - 1\n",
    "    E = -0.5 * np.einsum(\"bi,ij,bj->b\", spins, Jz, spins)  # -1/2 Σ_ij J_ij s_i s_j\n",
    "    return torch.tensor(E, dtype=torch.float64, device=samples.device)\n",
    "\n",
    "def train_wavefunction(config, model_class, device=\"cpu\"):\n",
    "\n",
    "    seed = config.seed\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed) \n",
    "\n",
    "    model = model_class(config).to(device)\n",
    "    opt = torch.optim.Adam(model.parameters(), lr=config.lr, weight_decay=0.0)\n",
    "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=(\n",
    "        config.num_warmup_steps + config.num_annealing_steps * config.num_equilibrium_steps\n",
    "    ), eta_min=config.lr * 0.1)\n",
    "\n",
    "    # Initialize Temperature and Steps\n",
    "    T, Bx = config.T0, config.Bx0\n",
    "    num_steps = config.num_warmup_steps + (config.num_annealing_steps * config.num_equilibrium_steps)\n",
    "    start = time.time()\n",
    "    for it in range(num_steps + 1):\n",
    "\n",
    "        # Linear Temperature Schedule\n",
    "        if it >= config.num_warmup_steps and it % config.num_equilibrium_steps == 0 and it <= config.num_annealing_steps*config.num_equilibrium_steps + config.num_warmup_steps:\n",
    "            anneal_k = (it - config.num_warmup_steps) / config.num_equilibrium_steps\n",
    "            T  = config.T0 * (1 - anneal_k / config.num_annealing_steps)\n",
    "            Bx = config.Bx0 * (1 - anneal_k / config.num_annealing_steps)\n",
    "            print(f\"\\nAnnealing Step: {anneal_k}/{config.num_annealing_steps}\")\n",
    "\n",
    "        # Sample SIGMA and Log Probabilities\n",
    "        with torch.no_grad():\n",
    "            spins, logp_seq = model.sample(config.numsamples)\n",
    "        \n",
    "        # Calculate Local Energy\n",
    "        E_local = local_energy_SK(config.Jz, spins).to(torch.float64)     # (B,)\n",
    "        logp_seq = logp_seq.to(torch.float64)                             # (B,)\n",
    "\n",
    "        # Print Statistics: Energy, Free Energy, Variance\n",
    "        free_local_energy = (E_local + T*logp_seq).detach()\n",
    "        if it%config.num_equilibrium_steps==0:\n",
    "            print(f'mean(E): {E_local.mean().item()}, mean(F): {free_local_energy.mean().item()}, var(E): {E_local.var().item()}, var(F): {free_local_energy.var().item()}, #samples {config.numsamples}, #Training step {it}')\n",
    "            print(\"Temperature: \", T)\n",
    "            print(\"Magnetic field: \", Bx)\n",
    "\n",
    "        # Inference at the end of Annealing\n",
    "        if it == config.num_annealing_steps*config.num_equilibrium_steps + config.num_warmup_steps:\n",
    "\n",
    "            numsamples_inference = 10**4 # Total number of samples at the end of annealing \n",
    "            Nsteps = 20 # number of steps to sample numsamples_inference\n",
    "            numsamples_perstep = numsamples_inference//Nsteps\n",
    "            energies = torch.zeros((numsamples_inference))\n",
    "            # solutions = torch.zeros((numsamples_inference, config.N))\n",
    "\n",
    "            print(\"\\nSaving energy and variance before the end of annealing\")\n",
    "            for i in range(Nsteps):\n",
    "                with torch.no_grad():\n",
    "                    spins, _ = model.sample(numsamples_perstep)\n",
    "                energies[i*numsamples_perstep:(i+1)*numsamples_perstep] = local_energy_SK(config.Jz, spins)\n",
    "                # solutions[i*numsamples_perstep:(i+1)*numsamples_perstep] = spins\n",
    "                print(f\"Sampling Step: {i+1}/{Nsteps}\")\n",
    "            print(\"meanE = \", energies.mean().item())\n",
    "            print(\"varE = \", energies.var().item())\n",
    "            print(\"minE = \", energies.min().item())\n",
    "\n",
    "            return energies.mean().item(), energies.min().item(), energies\n",
    "\n",
    "        logp_for_grad = model.log_probability(spins).to(torch.float64)\n",
    "        Floc = (E_local + T*logp_for_grad).detach()\n",
    "        loss = torch.mean(Floc * logp_for_grad) - torch.mean(logp_for_grad) * torch.mean(Floc)\n",
    "\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        # total_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        opt.step(); scheduler.step()\n",
    "\n",
    "        # ---- 打印 ----\n",
    "        if it % config.num_equilibrium_steps == 0:\n",
    "            print(f\"Grad Log Prob: {logp_for_grad.mean().item()}\")\n",
    "            print(f\"T*LogProb: {(T*logp_for_grad).mean().item()}\")\n",
    "            print(f\"Elapsed time = {time.time()-start:.2f} seconds\\n\")\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59841125",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using data/ising_chain_32_seed1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanyuuu/miniconda3/envs/TrsTorch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean(E): 0.1875, mean(F): -21.816055297851562, var(E): 32.21825396825397, var(F): 32.43516295131433, #samples 64, #Training step 0\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -22.00355550646782\n",
      "T*LogProb: -22.00355550646782\n",
      "Elapsed time = 0.47 seconds\n",
      "\n",
      "mean(E): -0.40625, mean(F): -22.415929317474365, var(E): 29.546626984126984, var(F): 28.867850776174034, #samples 64, #Training step 10\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -22.009679824113846\n",
      "T*LogProb: -22.009679824113846\n",
      "Elapsed time = 1.03 seconds\n",
      "\n",
      "mean(E): -0.03125, mean(F): -22.02250897884369, var(E): 41.64980158730159, var(F): 39.802894635316655, #samples 64, #Training step 20\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -21.991259276866913\n",
      "T*LogProb: -21.991259276866913\n",
      "Elapsed time = 1.71 seconds\n",
      "\n",
      "mean(E): 0.03125, mean(F): -21.770846635103226, var(E): 26.157738095238095, var(F): 24.46382399161717, #samples 64, #Training step 30\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -21.802096784114838\n",
      "T*LogProb: -21.802096784114838\n",
      "Elapsed time = 2.51 seconds\n",
      "\n",
      "mean(E): -1.4375, mean(F): -23.006777733564377, var(E): 37.01190476190476, var(F): 33.87245728512743, #samples 64, #Training step 40\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -21.569277942180634\n",
      "T*LogProb: -21.569277942180634\n",
      "Elapsed time = 3.28 seconds\n",
      "\n",
      "mean(E): 0.1875, mean(F): -21.776524633169174, var(E): 27.265873015873016, var(F): 24.61377958394263, #samples 64, #Training step 50\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -21.964024931192398\n",
      "T*LogProb: -21.964024931192398\n",
      "Elapsed time = 4.22 seconds\n",
      "\n",
      "mean(E): -0.71875, mean(F): -22.744147419929504, var(E): 29.189484126984127, var(F): 28.472882969800946, #samples 64, #Training step 60\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -22.02539750933647\n",
      "T*LogProb: -22.02539750933647\n",
      "Elapsed time = 4.96 seconds\n",
      "\n",
      "mean(E): -1.28125, mean(F): -23.33710315823555, var(E): 30.33234126984127, var(F): 28.97742155571499, #samples 64, #Training step 70\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -22.055853247642517\n",
      "T*LogProb: -22.055853247642517\n",
      "Elapsed time = 5.60 seconds\n",
      "\n",
      "mean(E): -1.09375, mean(F): -23.00478744506836, var(E): 24.94345238095238, var(F): 23.608933431120512, #samples 64, #Training step 80\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -21.91103747487068\n",
      "T*LogProb: -21.91103747487068\n",
      "Elapsed time = 6.26 seconds\n",
      "\n",
      "mean(E): -1.40625, mean(F): -23.491472899913788, var(E): 37.99107142857143, var(F): 35.50159886599307, #samples 64, #Training step 90\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -22.0852230489254\n",
      "T*LogProb: -22.0852230489254\n",
      "Elapsed time = 7.07 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 0.0/4\n",
      "mean(E): -2.21875, mean(F): -23.863480895757675, var(E): 25.348214285714285, var(F): 23.522907574486116, #samples 64, #Training step 100\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -21.644731104373932\n",
      "T*LogProb: -21.644731104373932\n",
      "Elapsed time = 7.97 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 1.0/4\n",
      "mean(E): -2.59375, mean(F): -18.95208689570427, var(E): 32.14980158730159, var(F): 30.682744804108214, #samples 64, #Training step 110\n",
      "Temperature:  0.75\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -21.811116129159927\n",
      "T*LogProb: -16.358337096869946\n",
      "Elapsed time = 8.69 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 2.0/4\n",
      "mean(E): -2.28125, mean(F): -13.204531759023666, var(E): 32.42757936507937, var(F): 30.33791523291992, #samples 64, #Training step 120\n",
      "Temperature:  0.5\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -21.846563816070557\n",
      "T*LogProb: -10.923281908035278\n",
      "Elapsed time = 9.59 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 3.0/4\n",
      "mean(E): -2.21875, mean(F): -7.649929352104664, var(E): 31.44345238095238, var(F): 30.62959892329585, #samples 64, #Training step 130\n",
      "Temperature:  0.25\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -21.724717438220978\n",
      "T*LogProb: -5.4311793595552444\n",
      "Elapsed time = 10.33 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 4.0/4\n",
      "mean(E): -1.1875, mean(F): -1.1875, var(E): 36.535714285714285, var(F): 36.535714285714285, #samples 64, #Training step 140\n",
      "Temperature:  0.0\n",
      "Magnetic field:  0.0\n",
      "\n",
      "Saving energy and variance before the end of annealing\n",
      "Sampling Step: 1/20\n",
      "Sampling Step: 2/20\n",
      "Sampling Step: 3/20\n",
      "Sampling Step: 4/20\n",
      "Sampling Step: 5/20\n",
      "Sampling Step: 6/20\n",
      "Sampling Step: 7/20\n",
      "Sampling Step: 8/20\n",
      "Sampling Step: 9/20\n",
      "Sampling Step: 10/20\n",
      "Sampling Step: 11/20\n",
      "Sampling Step: 12/20\n",
      "Sampling Step: 13/20\n",
      "Sampling Step: 14/20\n",
      "Sampling Step: 15/20\n",
      "Sampling Step: 16/20\n",
      "Sampling Step: 17/20\n",
      "Sampling Step: 18/20\n",
      "Sampling Step: 19/20\n",
      "Sampling Step: 20/20\n",
      "meanE =  -1.6128000020980835\n",
      "varE =  30.43712043762207\n",
      "minE =  -25.0\n",
      "using data/ising_chain_32_seed1.txt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanyuuu/miniconda3/envs/TrsTorch/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.norm_first was True\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean(E): 0.1875, mean(F): -21.816055297851562, var(E): 32.21825396825397, var(F): 32.43516295131433, #samples 64, #Training step 0\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -22.00355550646782\n",
      "T*LogProb: -22.00355550646782\n",
      "Elapsed time = 0.06 seconds\n",
      "\n",
      "mean(E): -0.40625, mean(F): -22.41593959927559, var(E): 29.546626984126984, var(F): 28.867711182241937, #samples 64, #Training step 10\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -22.00968998670578\n",
      "T*LogProb: -22.00968998670578\n",
      "Elapsed time = 0.84 seconds\n",
      "\n",
      "mean(E): -0.03125, mean(F): -22.022260189056396, var(E): 41.64980158730159, var(F): 39.79350449282518, #samples 64, #Training step 20\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -21.991010397672653\n",
      "T*LogProb: -21.991010397672653\n",
      "Elapsed time = 1.43 seconds\n",
      "\n",
      "mean(E): -0.03125, mean(F): -21.82400879263878, var(E): 26.28472222222222, var(F): 24.631023104222585, #samples 64, #Training step 30\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -21.792759031057358\n",
      "T*LogProb: -21.792759031057358\n",
      "Elapsed time = 2.07 seconds\n",
      "\n",
      "mean(E): -1.5625, mean(F): -23.134988993406296, var(E): 36.88492063492063, var(F): 33.834044870610285, #samples 64, #Training step 40\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -21.572489112615585\n",
      "T*LogProb: -21.572489112615585\n",
      "Elapsed time = 2.66 seconds\n",
      "\n",
      "mean(E): 0.03125, mean(F): -21.91956004500389, var(E): 27.55456349206349, var(F): 24.89394415165481, #samples 64, #Training step 50\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -21.95081028342247\n",
      "T*LogProb: -21.95081028342247\n",
      "Elapsed time = 3.34 seconds\n",
      "\n",
      "mean(E): -0.84375, mean(F): -22.905792206525803, var(E): 31.53075396825397, var(F): 30.35401759273621, #samples 64, #Training step 60\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -22.06204244494438\n",
      "T*LogProb: -22.06204244494438\n",
      "Elapsed time = 4.03 seconds\n",
      "\n",
      "mean(E): -1.375, mean(F): -23.406630039215088, var(E): 29.063492063492063, var(F): 27.330595926807348, #samples 64, #Training step 70\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -22.031630516052246\n",
      "T*LogProb: -22.031630516052246\n",
      "Elapsed time = 4.62 seconds\n",
      "\n",
      "mean(E): -1.09375, mean(F): -22.994722604751587, var(E): 25.197420634920636, var(F): 23.364611949875872, #samples 64, #Training step 80\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -21.9009727537632\n",
      "T*LogProb: -21.9009727537632\n",
      "Elapsed time = 5.26 seconds\n",
      "\n",
      "mean(E): -1.375, mean(F): -23.433803260326385, var(E): 38.07936507936508, var(F): 35.07187832898585, #samples 64, #Training step 90\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -22.058803468942642\n",
      "T*LogProb: -22.058803468942642\n",
      "Elapsed time = 5.83 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 0.0/8\n",
      "mean(E): -2.28125, mean(F): -23.857550531625748, var(E): 26.967261904761905, var(F): 25.23392263318941, #samples 64, #Training step 100\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -21.576300650835037\n",
      "T*LogProb: -21.576300650835037\n",
      "Elapsed time = 6.82 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 1.0/8\n",
      "mean(E): -2.90625, mean(F): -21.914825551211834, var(E): 33.83234126984127, var(F): 31.443899132668527, #samples 64, #Training step 110\n",
      "Temperature:  0.875\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -21.724086493253708\n",
      "T*LogProb: -19.008575681596994\n",
      "Elapsed time = 7.45 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 2.0/8\n",
      "mean(E): -2.8125, mean(F): -19.107904091477394, var(E): 34.25, var(F): 30.31999803339839, #samples 64, #Training step 120\n",
      "Temperature:  0.75\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -21.727205604314804\n",
      "T*LogProb: -16.295404203236103\n",
      "Elapsed time = 8.13 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 3.0/8\n",
      "mean(E): -2.9375, mean(F): -16.408842530101538, var(E): 34.28174603174603, var(F): 31.37583067841005, #samples 64, #Training step 130\n",
      "Temperature:  0.625\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -21.554148495197296\n",
      "T*LogProb: -13.47134280949831\n",
      "Elapsed time = 8.84 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 4.0/8\n",
      "mean(E): -2.03125, mean(F): -12.764735668897629, var(E): 38.60218253968254, var(F): 35.711762603310085, #samples 64, #Training step 140\n",
      "Temperature:  0.5\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -21.466971397399902\n",
      "T*LogProb: -10.733485698699951\n",
      "Elapsed time = 9.56 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 5.0/8\n",
      "mean(E): -1.6875, mean(F): -9.770450290292501, var(E): 27.583333333333332, var(F): 25.417279994209867, #samples 64, #Training step 150\n",
      "Temperature:  0.375\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -21.55453446507454\n",
      "T*LogProb: -8.082950424402952\n",
      "Elapsed time = 10.23 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 6.0/8\n",
      "mean(E): -3.46875, mean(F): -8.776304192841053, var(E): 18.506944444444443, var(F): 17.50348537206182, #samples 64, #Training step 160\n",
      "Temperature:  0.25\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -21.23021697998047\n",
      "T*LogProb: -5.307554244995117\n",
      "Elapsed time = 11.00 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 7.0/8\n",
      "mean(E): -2.53125, mean(F): -5.160772114992142, var(E): 41.87202380952381, var(F): 40.94445156237633, #samples 64, #Training step 170\n",
      "Temperature:  0.125\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -21.036177068948746\n",
      "T*LogProb: -2.629522133618593\n",
      "Elapsed time = 11.54 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 8.0/8\n",
      "mean(E): -2.625, mean(F): -2.625, var(E): 31.476190476190474, var(F): 31.476190476190474, #samples 64, #Training step 180\n",
      "Temperature:  0.0\n",
      "Magnetic field:  0.0\n",
      "\n",
      "Saving energy and variance before the end of annealing\n",
      "Sampling Step: 1/20\n",
      "Sampling Step: 2/20\n",
      "Sampling Step: 3/20\n",
      "Sampling Step: 4/20\n",
      "Sampling Step: 5/20\n",
      "Sampling Step: 6/20\n",
      "Sampling Step: 7/20\n",
      "Sampling Step: 8/20\n",
      "Sampling Step: 9/20\n",
      "Sampling Step: 10/20\n",
      "Sampling Step: 11/20\n",
      "Sampling Step: 12/20\n",
      "Sampling Step: 13/20\n",
      "Sampling Step: 14/20\n",
      "Sampling Step: 15/20\n",
      "Sampling Step: 16/20\n",
      "Sampling Step: 17/20\n",
      "Sampling Step: 18/20\n",
      "Sampling Step: 19/20\n",
      "Sampling Step: 20/20\n",
      "meanE =  -3.1589999198913574\n",
      "varE =  29.843704223632812\n",
      "minE =  -23.0\n",
      "using data/ising_chain_32_seed1.txt\n",
      "mean(E): 0.1875, mean(F): -21.816055297851562, var(E): 32.21825396825397, var(F): 32.43516295131433, #samples 64, #Training step 0\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -22.00355550646782\n",
      "T*LogProb: -22.00355550646782\n",
      "Elapsed time = 0.07 seconds\n",
      "\n",
      "mean(E): -0.40625, mean(F): -22.41594848036766, var(E): 29.546626984126984, var(F): 28.867589810652735, #samples 64, #Training step 10\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -22.009698450565338\n",
      "T*LogProb: -22.009698450565338\n",
      "Elapsed time = 1.12 seconds\n",
      "\n",
      "mean(E): -0.03125, mean(F): -22.022239804267883, var(E): 41.395833333333336, var(F): 39.7106456382112, #samples 64, #Training step 20\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -21.990989983081818\n",
      "T*LogProb: -21.990989983081818\n",
      "Elapsed time = 2.10 seconds\n",
      "\n",
      "mean(E): 0.03125, mean(F): -21.770721822977066, var(E): 26.157738095238095, var(F): 24.458119999090602, #samples 64, #Training step 30\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -21.801972150802612\n",
      "T*LogProb: -21.801972150802612\n",
      "Elapsed time = 2.88 seconds\n",
      "\n",
      "mean(E): -1.53125, mean(F): -23.072009652853012, var(E): 36.60218253968254, var(F): 33.35678130206271, #samples 64, #Training step 40\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -21.540759801864624\n",
      "T*LogProb: -21.540759801864624\n",
      "Elapsed time = 3.49 seconds\n",
      "\n",
      "mean(E): 0.09375, mean(F): -21.859601974487305, var(E): 27.165674603174605, var(F): 24.57941752589954, #samples 64, #Training step 50\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -21.953352093696594\n",
      "T*LogProb: -21.953352093696594\n",
      "Elapsed time = 4.27 seconds\n",
      "\n",
      "mean(E): -0.90625, mean(F): -22.988423496484756, var(E): 30.78472222222222, var(F): 29.388367010358888, #samples 64, #Training step 60\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -22.082173973321915\n",
      "T*LogProb: -22.082173973321915\n",
      "Elapsed time = 5.24 seconds\n",
      "\n",
      "mean(E): -1.5625, mean(F): -23.575916826725006, var(E): 30.66269841269841, var(F): 28.616801577865566, #samples 64, #Training step 70\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -22.013416975736618\n",
      "T*LogProb: -22.013416975736618\n",
      "Elapsed time = 6.14 seconds\n",
      "\n",
      "mean(E): -0.9375, mean(F): -22.84768435359001, var(E): 25.265873015873016, var(F): 23.33813395117616, #samples 64, #Training step 80\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -21.91018494963646\n",
      "T*LogProb: -21.91018494963646\n",
      "Elapsed time = 6.80 seconds\n",
      "\n",
      "mean(E): -1.53125, mean(F): -23.574389845132828, var(E): 40.03075396825397, var(F): 36.20242242114998, #samples 64, #Training step 90\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -22.043139934539795\n",
      "T*LogProb: -22.043139934539795\n",
      "Elapsed time = 7.60 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 0.0/16\n",
      "mean(E): -2.75, mean(F): -24.156459033489227, var(E): 27.238095238095237, var(F): 24.329811525703047, #samples 64, #Training step 100\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -21.40645906329155\n",
      "T*LogProb: -21.40645906329155\n",
      "Elapsed time = 8.20 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 1.0/16\n",
      "mean(E): -3.4375, mean(F): -23.666558787226677, var(E): 34.726190476190474, var(F): 31.308184828717458, #samples 64, #Training step 110\n",
      "Temperature:  0.9375\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -21.57766282558441\n",
      "T*LogProb: -20.229058898985386\n",
      "Elapsed time = 9.05 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 2.0/16\n",
      "mean(E): -3.4375, mean(F): -22.283827178180218, var(E): 36.12301587301587, var(F): 29.68550103148075, #samples 64, #Training step 120\n",
      "Temperature:  0.875\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -21.538659900426865\n",
      "T*LogProb: -18.846327412873507\n",
      "Elapsed time = 9.80 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 3.0/16\n",
      "mean(E): -4.59375, mean(F): -21.684018526226282, var(E): 32.276785714285715, var(F): 26.975099134804932, #samples 64, #Training step 130\n",
      "Temperature:  0.8125\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -21.034177273511887\n",
      "T*LogProb: -17.090269034728408\n",
      "Elapsed time = 10.51 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 4.0/16\n",
      "mean(E): -3.8125, mean(F): -19.50798148661852, var(E): 39.20238095238095, var(F): 33.08211410192335, #samples 64, #Training step 140\n",
      "Temperature:  0.75\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -20.927308917045593\n",
      "T*LogProb: -15.695481687784195\n",
      "Elapsed time = 11.24 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 5.0/16\n",
      "mean(E): -4.21875, mean(F): -18.410082068294287, var(E): 29.411706349206348, var(F): 23.382386768202704, #samples 64, #Training step 150\n",
      "Temperature:  0.6875\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -20.641937851905823\n",
      "T*LogProb: -14.191332273185253\n",
      "Elapsed time = 11.96 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 6.0/16\n",
      "mean(E): -5.5625, mean(F): -18.049582667648792, var(E): 21.265873015873016, var(F): 16.46743262303249, #samples 64, #Training step 160\n",
      "Temperature:  0.625\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -19.979332268238068\n",
      "T*LogProb: -12.487082667648792\n",
      "Elapsed time = 12.98 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 7.0/16\n",
      "mean(E): -5.8125, mean(F): -16.907691705040634, var(E): 42.88492063492063, var(F): 34.67326718348189, #samples 64, #Training step 170\n",
      "Temperature:  0.5625\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -19.724785447120667\n",
      "T*LogProb: -11.095191814005375\n",
      "Elapsed time = 13.58 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 8.0/16\n",
      "mean(E): -7.03125, mean(F): -16.79690957814455, var(E): 31.046626984126984, var(F): 24.65328450148107, #samples 64, #Training step 180\n",
      "Temperature:  0.5\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -19.531319350004196\n",
      "T*LogProb: -9.765659675002098\n",
      "Elapsed time = 14.37 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 9.0/16\n",
      "mean(E): -8.75, mean(F): -16.911804475821555, var(E): 20.50793650793651, var(F): 16.38038111222671, #samples 64, #Training step 190\n",
      "Temperature:  0.4375\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -18.655553326010704\n",
      "T*LogProb: -8.161804580129683\n",
      "Elapsed time = 15.52 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 10.0/16\n",
      "mean(E): -8.75, mean(F): -15.637841124087572, var(E): 25.206349206349206, var(F): 19.929084255378896, #samples 64, #Training step 200\n",
      "Temperature:  0.375\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -18.367576703429222\n",
      "T*LogProb: -6.887841263785958\n",
      "Elapsed time = 16.10 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 11.0/16\n",
      "mean(E): -10.03125, mean(F): -15.646934860385954, var(E): 21.713293650793652, var(F): 17.791836691516032, #samples 64, #Training step 210\n",
      "Temperature:  0.3125\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -17.970191791653633\n",
      "T*LogProb: -5.61568493489176\n",
      "Elapsed time = 17.18 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 12.0/16\n",
      "mean(E): -10.875, mean(F): -15.200234547257423, var(E): 30.333333333333332, var(F): 26.864712671470702, #samples 64, #Training step 220\n",
      "Temperature:  0.25\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -17.3009385317564\n",
      "T*LogProb: -4.3252346329391\n",
      "Elapsed time = 18.11 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 13.0/16\n",
      "mean(E): -10.3125, mean(F): -13.485443727113307, var(E): 30.63095238095238, var(F): 26.131701365763167, #samples 64, #Training step 230\n",
      "Temperature:  0.1875\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -16.922367185354233\n",
      "T*LogProb: -3.1729438472539186\n",
      "Elapsed time = 18.76 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 14.0/16\n",
      "mean(E): -11.09375, mean(F): -13.160660304129124, var(E): 26.086309523809526, var(F): 23.69168986279755, #samples 64, #Training step 240\n",
      "Temperature:  0.125\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -16.53528267145157\n",
      "T*LogProb: -2.066910333931446\n",
      "Elapsed time = 19.48 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 15.0/16\n",
      "mean(E): -11.90625, mean(F): -12.923124076798558, var(E): 26.53075396825397, var(F): 25.244829330505354, #samples 64, #Training step 250\n",
      "Temperature:  0.0625\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -16.269985511898994\n",
      "T*LogProb: -1.0168740944936872\n",
      "Elapsed time = 19.98 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 16.0/16\n",
      "mean(E): -12.15625, mean(F): -12.15625, var(E): 19.78472222222222, var(F): 19.78472222222222, #samples 64, #Training step 260\n",
      "Temperature:  0.0\n",
      "Magnetic field:  0.0\n",
      "\n",
      "Saving energy and variance before the end of annealing\n",
      "Sampling Step: 1/20\n",
      "Sampling Step: 2/20\n",
      "Sampling Step: 3/20\n",
      "Sampling Step: 4/20\n",
      "Sampling Step: 5/20\n",
      "Sampling Step: 6/20\n",
      "Sampling Step: 7/20\n",
      "Sampling Step: 8/20\n",
      "Sampling Step: 9/20\n",
      "Sampling Step: 10/20\n",
      "Sampling Step: 11/20\n",
      "Sampling Step: 12/20\n",
      "Sampling Step: 13/20\n",
      "Sampling Step: 14/20\n",
      "Sampling Step: 15/20\n",
      "Sampling Step: 16/20\n",
      "Sampling Step: 17/20\n",
      "Sampling Step: 18/20\n",
      "Sampling Step: 19/20\n",
      "Sampling Step: 20/20\n",
      "meanE =  -12.323800086975098\n",
      "varE =  25.524105072021484\n",
      "minE =  -27.0\n",
      "using data/ising_chain_32_seed1.txt\n",
      "mean(E): 0.1875, mean(F): -21.816055297851562, var(E): 32.21825396825397, var(F): 32.43516295131433, #samples 64, #Training step 0\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -22.00355550646782\n",
      "T*LogProb: -22.00355550646782\n",
      "Elapsed time = 0.06 seconds\n",
      "\n",
      "mean(E): -0.40625, mean(F): -22.415953636169434, var(E): 29.546626984126984, var(F): 28.867530310065334, #samples 64, #Training step 10\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -22.00970384478569\n",
      "T*LogProb: -22.00970384478569\n",
      "Elapsed time = 0.76 seconds\n",
      "\n",
      "mean(E): -0.03125, mean(F): -22.02217936515808, var(E): 41.395833333333336, var(F): 39.70788980989678, #samples 64, #Training step 20\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -21.990929663181305\n",
      "T*LogProb: -21.990929663181305\n",
      "Elapsed time = 1.38 seconds\n",
      "\n",
      "mean(E): -0.03125, mean(F): -21.823913127183914, var(E): 26.28472222222222, var(F): 24.621991942402193, #samples 64, #Training step 30\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -21.79266330599785\n",
      "T*LogProb: -21.79266330599785\n",
      "Elapsed time = 2.50 seconds\n",
      "\n",
      "mean(E): -1.625, mean(F): -23.16699370741844, var(E): 37.82539682539682, var(F): 34.653177856270084, #samples 64, #Training step 40\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -21.541994094848633\n",
      "T*LogProb: -21.541994094848633\n",
      "Elapsed time = 3.17 seconds\n",
      "\n",
      "mean(E): 0.0625, mean(F): -21.88331925868988, var(E): 27.805555555555557, var(F): 25.10649726755714, #samples 64, #Training step 50\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -21.945819914340973\n",
      "T*LogProb: -21.945819914340973\n",
      "Elapsed time = 3.83 seconds\n",
      "\n",
      "mean(E): -0.84375, mean(F): -22.90560033917427, var(E): 30.514880952380953, var(F): 29.06719848662652, #samples 64, #Training step 60\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -22.061850607395172\n",
      "T*LogProb: -22.061850607395172\n",
      "Elapsed time = 4.51 seconds\n",
      "\n",
      "mean(E): -1.5, mean(F): -23.486942648887634, var(E): 29.96825396825397, var(F): 27.708933774262675, #samples 64, #Training step 70\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -21.986942917108536\n",
      "T*LogProb: -21.986942917108536\n",
      "Elapsed time = 5.27 seconds\n",
      "\n",
      "mean(E): -0.96875, mean(F): -22.857833594083786, var(E): 25.967261904761905, var(F): 24.14710775833926, #samples 64, #Training step 80\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -21.88908377289772\n",
      "T*LogProb: -21.88908377289772\n",
      "Elapsed time = 6.07 seconds\n",
      "\n",
      "mean(E): -1.5625, mean(F): -23.60287407040596, var(E): 39.932539682539684, var(F): 35.87836409914117, #samples 64, #Training step 90\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -22.04037430882454\n",
      "T*LogProb: -22.04037430882454\n",
      "Elapsed time = 6.79 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 0.0/32\n",
      "mean(E): -2.90625, mean(F): -24.27212992310524, var(E): 27.356150793650794, var(F): 24.020565029335664, #samples 64, #Training step 100\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -21.365880012512207\n",
      "T*LogProb: -21.365880012512207\n",
      "Elapsed time = 7.59 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 1.0/32\n",
      "mean(E): -4.21875, mean(F): -25.026093394495547, var(E): 35.88789682539682, var(F): 31.59022114601099, #samples 64, #Training step 110\n",
      "Temperature:  0.96875\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -21.478548407554626\n",
      "T*LogProb: -20.807343769818544\n",
      "Elapsed time = 8.47 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 2.0/32\n",
      "mean(E): -3.6875, mean(F): -23.662674935534596, var(E): 37.86904761904762, var(F): 29.83408145653776, #samples 64, #Training step 120\n",
      "Temperature:  0.9375\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -21.306853592395782\n",
      "T*LogProb: -19.975175242871046\n",
      "Elapsed time = 9.24 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 3.0/32\n",
      "mean(E): -5.53125, mean(F): -24.348290905356407, var(E): 32.28472222222222, var(F): 25.553484616687662, #samples 64, #Training step 130\n",
      "Temperature:  0.90625\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -20.7636316716671\n",
      "T*LogProb: -18.81704120244831\n",
      "Elapsed time = 10.03 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 4.0/32\n",
      "mean(E): -5.6875, mean(F): -23.362411092966795, var(E): 36.47222222222222, var(F): 28.054681732335915, #samples 64, #Training step 140\n",
      "Temperature:  0.875\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -20.199898689985275\n",
      "T*LogProb: -17.674911353737116\n",
      "Elapsed time = 10.78 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 5.0/32\n",
      "mean(E): -7.6875, mean(F): -23.829499311279505, var(E): 36.59920634920635, var(F): 25.761873882312802, #samples 64, #Training step 150\n",
      "Temperature:  0.84375\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -19.1312585324049\n",
      "T*LogProb: -16.141999386716634\n",
      "Elapsed time = 11.49 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 6.0/32\n",
      "mean(E): -8.84375, mean(F): -23.710333282127976, var(E): 16.419642857142858, var(F): 11.212705811345849, #samples 64, #Training step 160\n",
      "Temperature:  0.8125\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -18.297333478927612\n",
      "T*LogProb: -14.866583451628685\n",
      "Elapsed time = 12.14 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 7.0/32\n",
      "mean(E): -10.78125, mean(F): -24.498524519149214, var(E): 32.01488095238095, var(F): 19.403919673281823, #samples 64, #Training step 170\n",
      "Temperature:  0.78125\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -17.558111518621445\n",
      "T*LogProb: -13.717274623923004\n",
      "Elapsed time = 12.93 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 8.0/32\n",
      "mean(E): -12.9375, mean(F): -25.11881073564291, var(E): 25.646825396825395, var(F): 13.700736640980434, #samples 64, #Training step 180\n",
      "Temperature:  0.75\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -16.241748064756393\n",
      "T*LogProb: -12.181311048567295\n",
      "Elapsed time = 13.53 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 9.0/32\n",
      "mean(E): -14.9375, mean(F): -25.670658363495022, var(E): 26.66269841269841, var(F): 12.083356477734423, #samples 64, #Training step 190\n",
      "Temperature:  0.71875\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -14.933090090751648\n",
      "T*LogProb: -10.733158502727747\n",
      "Elapsed time = 14.26 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 10.0/32\n",
      "mean(E): -16.625, mean(F): -25.974587683565915, var(E): 18.015873015873016, var(F): 9.992167440653787, #samples 64, #Training step 200\n",
      "Temperature:  0.6875\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -13.599400371313095\n",
      "T*LogProb: -9.349587755277753\n",
      "Elapsed time = 15.04 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 11.0/32\n",
      "mean(E): -18.21875, mean(F): -26.53080076118931, var(E): 24.967261904761905, var(F): 10.758466792822556, #samples 64, #Training step 210\n",
      "Temperature:  0.65625\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -12.66598229110241\n",
      "T*LogProb: -8.312050878535956\n",
      "Elapsed time = 15.74 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 12.0/32\n",
      "mean(E): -19.9375, mean(F): -27.184375213459134, var(E): 19.424603174603174, var(F): 9.231167040869197, #samples 64, #Training step 220\n",
      "Temperature:  0.625\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -11.595000587403774\n",
      "T*LogProb: -7.246875367127359\n",
      "Elapsed time = 16.45 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 13.0/32\n",
      "mean(E): -20.78125, mean(F): -27.203591281315312, var(E): 14.364087301587302, var(F): 6.8592239341047785, #samples 64, #Training step 230\n",
      "Temperature:  0.59375\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -10.816575177013874\n",
      "T*LogProb: -6.422341511351988\n",
      "Elapsed time = 17.15 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 14.0/32\n",
      "mean(E): -22.3125, mean(F): -27.494882601778954, var(E): 14.376984126984127, var(F): 5.46765484426289, #samples 64, #Training step 240\n",
      "Temperature:  0.5625\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -9.21312478929758\n",
      "T*LogProb: -5.182382693979889\n",
      "Elapsed time = 17.76 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 15.0/32\n",
      "mean(E): -22.15625, mean(F): -27.074707356048748, var(E): 13.689484126984127, var(F): 5.569886063186546, #samples 64, #Training step 250\n",
      "Temperature:  0.53125\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -9.258273102343082\n",
      "T*LogProb: -4.9184575856197625\n",
      "Elapsed time = 18.62 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 16.0/32\n",
      "mean(E): -23.125, mean(F): -27.585606776177883, var(E): 18.015873015873016, var(F): 6.807877344372841, #samples 64, #Training step 260\n",
      "Temperature:  0.5\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -8.921213559806347\n",
      "T*LogProb: -4.4606067799031734\n",
      "Elapsed time = 19.35 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 17.0/32\n",
      "mean(E): -23.90625, mean(F): -27.70992008736357, var(E): 12.054563492063492, var(F): 5.093498703742522, #samples 64, #Training step 270\n",
      "Temperature:  0.46875\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -8.11449646577239\n",
      "T*LogProb: -3.803670218330808\n",
      "Elapsed time = 19.94 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 18.0/32\n",
      "mean(E): -24.3125, mean(F): -27.802978628547862, var(E): 11.329365079365079, var(F): 5.189481205136184, #samples 64, #Training step 280\n",
      "Temperature:  0.4375\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -7.978237047791481\n",
      "T*LogProb: -3.490478708408773\n",
      "Elapsed time = 20.70 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 19.0/32\n",
      "mean(E): -25.625, mean(F): -28.384268334601074, var(E): 10.904761904761905, var(F): 5.6853302388074995, #samples 64, #Training step 290\n",
      "Temperature:  0.40625\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -6.792045194655657\n",
      "T*LogProb: -2.7592683603288606\n",
      "Elapsed time = 21.58 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 20.0/32\n",
      "mean(E): -25.21875, mean(F): -27.77638833783567, var(E): 9.919642857142858, var(F): 4.6924838796119595, #samples 64, #Training step 300\n",
      "Temperature:  0.375\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -6.820369090884924\n",
      "T*LogProb: -2.5576384090818465\n",
      "Elapsed time = 22.30 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 21.0/32\n",
      "mean(E): -26.28125, mean(F): -28.403629180043936, var(E): 9.570436507936508, var(F): 4.74369444978365, #samples 64, #Training step 310\n",
      "Temperature:  0.34375\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -6.174194321036339\n",
      "T*LogProb: -2.1223792978562415\n",
      "Elapsed time = 23.39 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 22.0/32\n",
      "mean(E): -26.78125, mean(F): -28.512135478900746, var(E): 10.808531746031745, var(F): 5.702224303823665, #samples 64, #Training step 320\n",
      "Temperature:  0.3125\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -5.538833927363157\n",
      "T*LogProb: -1.7308856023009866\n",
      "Elapsed time = 23.99 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 23.0/32\n",
      "mean(E): -26.75, mean(F): -28.291258548619226, var(E): 9.206349206349206, var(F): 5.125264679827852, #samples 64, #Training step 330\n",
      "Temperature:  0.28125\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -5.4800307508558035\n",
      "T*LogProb: -1.5412586486781947\n",
      "Elapsed time = 24.64 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 24.0/32\n",
      "mean(E): -26.78125, mean(F): -28.169682796113193, var(E): 12.71329365079365, var(F): 7.0466175612983495, #samples 64, #Training step 340\n",
      "Temperature:  0.25\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -5.553731188178062\n",
      "T*LogProb: -1.3884327970445156\n",
      "Elapsed time = 25.33 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 25.0/32\n",
      "mean(E): -26.71875, mean(F): -27.95511566498317, var(E): 7.983134920634921, var(F): 4.872924654967497, #samples 64, #Training step 350\n",
      "Temperature:  0.21875\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -5.651957422494888\n",
      "T*LogProb: -1.2363656861707568\n",
      "Elapsed time = 26.00 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 26.0/32\n",
      "mean(E): -27.375, mean(F): -28.285830850945786, var(E): 6.333333333333333, var(F): 4.096121006979347, #samples 64, #Training step 360\n",
      "Temperature:  0.1875\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -4.857764596119523\n",
      "T*LogProb: -0.9108308617724106\n",
      "Elapsed time = 26.62 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 27.0/32\n",
      "mean(E): -27.4375, mean(F): -28.21740879828576, var(E): 11.234126984126984, var(F): 7.866100224522954, #samples 64, #Training step 370\n",
      "Temperature:  0.15625\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -4.9914161041378975\n",
      "T*LogProb: -0.7799087662715465\n",
      "Elapsed time = 27.25 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 28.0/32\n",
      "mean(E): -28.15625, mean(F): -28.658244435675442, var(E): 6.578373015873016, var(F): 4.909217719109147, #samples 64, #Training step 380\n",
      "Temperature:  0.125\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -4.0159556325525045\n",
      "T*LogProb: -0.5019944540690631\n",
      "Elapsed time = 27.99 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 29.0/32\n",
      "mean(E): -28.71875, mean(F): -29.031039769528434, var(E): 5.570436507936508, var(F): 4.486048601329082, #samples 64, #Training step 390\n",
      "Temperature:  0.09375\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -3.3310911655426025\n",
      "T*LogProb: -0.312289796769619\n",
      "Elapsed time = 28.76 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 30.0/32\n",
      "mean(E): -28.21875, mean(F): -28.46984937111847, var(E): 6.554563492063492, var(F): 5.698856115779411, #samples 64, #Training step 400\n",
      "Temperature:  0.0625\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -4.017589960247278\n",
      "T*LogProb: -0.2510993725154549\n",
      "Elapsed time = 29.51 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 31.0/32\n",
      "mean(E): -28.90625, mean(F): -29.005888438317925, var(E): 4.372023809523809, var(F): 4.066892005186221, #samples 64, #Training step 410\n",
      "Temperature:  0.03125\n",
      "Magnetic field:  0.0\n",
      "Grad Log Prob: -3.188429811038077\n",
      "T*LogProb: -0.0996384315949399\n",
      "Elapsed time = 30.23 seconds\n",
      "\n",
      "\n",
      "Annealing Step: 32.0/32\n",
      "mean(E): -28.53125, mean(F): -28.53125, var(E): 7.078373015873016, var(F): 7.078373015873016, #samples 64, #Training step 420\n",
      "Temperature:  0.0\n",
      "Magnetic field:  0.0\n",
      "\n",
      "Saving energy and variance before the end of annealing\n",
      "Sampling Step: 1/20\n",
      "Sampling Step: 2/20\n",
      "Sampling Step: 3/20\n",
      "Sampling Step: 4/20\n",
      "Sampling Step: 5/20\n",
      "Sampling Step: 6/20\n",
      "Sampling Step: 7/20\n",
      "Sampling Step: 8/20\n",
      "Sampling Step: 9/20\n",
      "Sampling Step: 10/20\n",
      "Sampling Step: 11/20\n",
      "Sampling Step: 12/20\n",
      "Sampling Step: 13/20\n",
      "Sampling Step: 14/20\n",
      "Sampling Step: 15/20\n",
      "Sampling Step: 16/20\n",
      "Sampling Step: 17/20\n",
      "Sampling Step: 18/20\n",
      "Sampling Step: 19/20\n",
      "Sampling Step: 20/20\n",
      "meanE =  -28.71299934387207\n",
      "varE =  6.226653575897217\n",
      "minE =  -31.0\n",
      "using data/ising_chain_32_seed1.txt\n",
      "mean(E): 0.1875, mean(F): -21.816055297851562, var(E): 32.21825396825397, var(F): 32.43516295131433, #samples 64, #Training step 0\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -22.00355550646782\n",
      "T*LogProb: -22.00355550646782\n",
      "Elapsed time = 0.05 seconds\n",
      "\n",
      "mean(E): -0.40625, mean(F): -22.415955305099487, var(E): 29.546626984126984, var(F): 28.867499741636752, #samples 64, #Training step 10\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -22.009705513715744\n",
      "T*LogProb: -22.009705513715744\n",
      "Elapsed time = 1.00 seconds\n",
      "\n",
      "mean(E): -0.03125, mean(F): -22.022149324417114, var(E): 41.395833333333336, var(F): 39.706780336312576, #samples 64, #Training step 20\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -21.99089965224266\n",
      "T*LogProb: -21.99089965224266\n",
      "Elapsed time = 2.00 seconds\n",
      "\n",
      "mean(E): -0.03125, mean(F): -21.823835611343384, var(E): 26.28472222222222, var(F): 24.623940371556518, #samples 64, #Training step 30\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -21.792585611343384\n",
      "T*LogProb: -21.792585611343384\n",
      "Elapsed time = 2.83 seconds\n",
      "\n",
      "mean(E): -1.625, mean(F): -23.167401880025864, var(E): 37.82539682539682, var(F): 34.63692642100602, #samples 64, #Training step 40\n",
      "Temperature:  1.0\n",
      "Magnetic field:  0\n",
      "Grad Log Prob: -21.54240196943283\n",
      "T*LogProb: -21.54240196943283\n",
      "Elapsed time = 3.74 seconds\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "for exp in range(2, 8):\n",
    "    anneal = 2**exp\n",
    "\n",
    "    energy_list = []\n",
    "    for seed in range(1, 2):\n",
    "        config = SimpleConfig(f\"data/ising_chain_32_seed{seed}.txt\")\n",
    "        config.seed = seed\n",
    "        config.num_annealing_steps = anneal\n",
    "\n",
    "        meanE, meanFm, energy = train_wavefunction(\n",
    "            config,\n",
    "            model_class=TransformerWavefunction, \n",
    "            device=device,\n",
    "        )\n",
    "\n",
    "        energy_list.append(f\"{meanE}\\n\")\n",
    "        with open(f\"TRANSFORMER_chain_{32}_{anneal}.txt\", \"w\") as f:\n",
    "            f.writelines(energy_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e3e08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def plot_histogram(energies, config, gsenergy_per_spin):\n",
    "\n",
    "    N = config.num_nodes\n",
    "    num_annealing_steps = config.num_annealing_steps\n",
    "\n",
    "    if isinstance(energies, torch.Tensor):\n",
    "        energies = energies.cpu().numpy()\n",
    "\n",
    "    gsenergy = gsenergy_per_spin * N\n",
    "\n",
    "    MIN, MAX = 1e-10, 1.0\n",
    "    tol = 1e-10\n",
    "\n",
    "    eres = (energies - gsenergy) / N\n",
    "    eres[eres <= 0.0] = tol \n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.hist(eres, alpha=0.9, color='b', bins=10**np.linspace(np.log10(MIN), np.log10(MAX), 20), label=f'$N_{{annealing}}={num_annealing_steps}$')\n",
    "    \n",
    "    plt.gca().set_xscale(\"log\")\n",
    "    plt.ylim(0, len(energies))\n",
    "    plt.legend(loc='best', frameon=False)\n",
    "    plt.xlabel(r'$\\epsilon_{res}/N$')\n",
    "    plt.ylabel('Count')\n",
    "    plt.title('Residual Energy Distribution')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8757e7-eebe-48ca-8e6b-08695d743a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "GS_ENERGY_PER_SPIN_benchmark = meanFm / config.num_nodes\n",
    "\n",
    "plot_histogram(energies, config, GS_ENERGY_PER_SPIN_benchmark)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
