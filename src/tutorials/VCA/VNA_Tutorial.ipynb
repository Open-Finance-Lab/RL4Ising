{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99676ca3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/lin/miniconda3/envs/vca/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/lin/miniconda3/envs/vca/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/lin/miniconda3/envs/vca/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/lin/miniconda3/envs/vca/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/lin/miniconda3/envs/vca/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/lin/miniconda3/envs/vca/lib/python3.7/site-packages/tensorflow/python/framework/dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported local modules.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "from math import sqrt\n",
    "\n",
    "try:\n",
    "    from config import config\n",
    "    from DilatedRNN import DilatedRNNWavefunction\n",
    "    from utils import Fullyconnected_localenergies, Fullyconnected_diagonal_matrixelements\n",
    "    from vca import vca_solver\n",
    "    print(\"Successfully imported local modules.\")\n",
    "except ImportError:\n",
    "    print(\"Local .py files not found. Please ensure they are in the same directory or paste the classes below.\")\n",
    "\n",
    "tf.compat.v1.disable_eager_execution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b676f9fb",
   "metadata": {},
   "source": [
    "# Section 1: Ising Model as Energy Minimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c29caa",
   "metadata": {},
   "source": [
    "## 1.1 What is the Ising Model?\n",
    "The Ising model was originally developed in statistical physics to describe the **ferromagnetism** of solid materials. It assumes that a system consists of a collection of **spins** arranged on a lattice, where each spin can only take one of two discrete values:\n",
    "* $s_i = +1$ (Spin Up)\n",
    "* $s_i = -1$ (Spin Down)\n",
    "\n",
    "In this implementation, the spins are mapped to binary values $s \\in \\{0, 1\\}$ to be compatible with neural network processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c98273",
   "metadata": {},
   "source": [
    "## 1.2 Problem Type: Combinatorial Optimization\n",
    "From a computer science perspective, the Ising model is a classic **Combinatorial Optimization Problem**:\n",
    "* **Goal**: To find a specific arrangement among $2^N$ possible discrete configurations that minimizes the total energy of the system.\n",
    "* **Applications**: Many famous NP-hard problems, such as the **Max-Cut Problem**, **Traveling Salesperson Problem (TSP)**, or **Graph Coloring**, can be exactly mapped onto the energy minimization of an Ising model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50879217",
   "metadata": {},
   "source": [
    "## 1.3 Mathematical Nature & The Hamiltonian\n",
    "The **Hamiltonian** is a function in physics that represents the total energy of a system. For a fully connected Ising model, the energy function $E(\\mathbf{s})$ is defined as:\n",
    "\n",
    "$$E(\\mathbf{s}) = -\\sum_{i < j} J_{ij} \\sigma_i \\sigma_j - \\sum_i h_i \\sigma_i$$\n",
    "\n",
    "* **$J_{ij}$ (Interaction Term)**: Defines the coupling strength between spins $i$ and $j$.\n",
    "    * If $J_{ij} > 0$: Spins tend to align in the same direction (Ferromagnetic).\n",
    "    * If $J_{ij} < 0$: Spins tend to align in opposite directions (Anti-ferromagnetic).\n",
    "* **$h_i$ (External Field)**: Represents the influence of an external magnetic field or bias on an individual spin. In this code, a transverse field `Bx` is introduced to add non-diagonal perturbations.\n",
    "* **Code Example**: In `utils.py`, the `Jz` matrix stores all interaction weights, and the function `Fullyconnected_diagonal_matrixelements` calculates the classical energy based on these weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d8c6d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Fullyconnected_diagonal_matrixelements(Jz, samples):\n",
    "    numsamples = samples.shape[0]\n",
    "    N = samples.shape[1]\n",
    "    energies = np.zeros((numsamples), dtype = np.float64)\n",
    "\n",
    "    for i in range(N-1):\n",
    "      values = np.expand_dims(samples[:,i], axis = -1)+samples[:,i+1:]\n",
    "      valuesT = np.copy(values)\n",
    "      valuesT[values==2] = +1 #If both spins are up\n",
    "      valuesT[values==0] = +1 #If both spins are down\n",
    "      valuesT[values==1] = -1 #If they are opposite\n",
    "\n",
    "      energies += np.sum(valuesT*(-Jz[i,i+1:]), axis = 1)\n",
    "\n",
    "    return energies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad844f1b",
   "metadata": {},
   "source": [
    "## 1.4 The Essence of NP-hardness\n",
    "Finding the lowest energy state (the **Ground State**) of an Ising model is extremely difficult for the following reasons:\n",
    "\n",
    "1.  **Exponential State Space**: For $N$ spins, there are $2^N$ possible states. Brute-force search becomes impossible as $N$ grows.\n",
    "2.  **Frustration**: When the distribution of $J_{ij}$ is complex (as in Spin Glass models), the system cannot satisfy all coupling terms simultaneously.\n",
    "3.  **Complex Energy Landscape**: Frustration leads to a highly non-convex energy landscape filled with numerous **Local Minima**.\n",
    "4.  **Mathematical Bottleneck**: Due to these high energy barriers, traditional optimization algorithms easily get stuck in local optima, failing to find the global optimum. This is the core of its NP-hardness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6f170a",
   "metadata": {},
   "source": [
    "# Section 2: From Simulated Annealing to Variational Formulation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31b76a40",
   "metadata": {},
   "source": [
    "## 2.1 The Boltzmann Distribution\n",
    "In statistical mechanics, a system at thermal equilibrium at temperature $T$ is described by the **Boltzmann distribution**. The probability of the system being in a specific state $\\mathbf{s}$ is given by:\n",
    "\n",
    "$$P_B(\\mathbf{s}) = \\frac{e^{-E(\\mathbf{s})/T}}{Z}$$\n",
    "\n",
    "* **$E(\\mathbf{s})$**: The energy of configuration $\\mathbf{s}$.\n",
    "* **$T$**: The temperature (effectively controlling the \"noise\" level).\n",
    "* **$Z$**: The partition function $Z = \\sum_{\\mathbf{s}} e^{-E(\\mathbf{s})/T}$, which ensures the total probability sums to 1.\n",
    "\n",
    "**Physical Intuition**: \n",
    "* At **high temperatures**, $P_B(\\mathbf{s})$ becomes nearly uniform, allowing the system to explore the state space freely.\n",
    "* At **low temperatures** ($T \\to 0$), the distribution concentrates all its probability mass on the **Ground State** (the global minimum of energy)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0dbef3",
   "metadata": {},
   "source": [
    "## 2.2 Motivation: Why Variational?\n",
    "Traditional **Simulated Annealing (SA)** relies on Markov Chain Monte Carlo (MCMC) sampling. However, SA faces significant challenges:\n",
    "1.  **Mixing Time**: In complex energy landscapes (like Spin Glasses), MCMC can get trapped in local minima for an exponentially long time.\n",
    "2.  **Normalization**: Calculating the partition function $Z$ is computationally intractable for large systems.\n",
    "\n",
    "**The Variational Solution**:\n",
    "Instead of using MCMC to sample from the unknown $P_B(\\mathbf{s})$, we introduce a **Variational Distribution** $q_\\theta(\\mathbf{s})$ (represented by our Neural Network). We then optimize the parameters $\\theta$ to make $q_\\theta(\\mathbf{s})$ as close as possible to the target Boltzmann distribution $P_B(\\mathbf{s})$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15ac4c4",
   "metadata": {},
   "source": [
    "## 2.3 The Objective: Minimizing Free Energy\n",
    "The \"closeness\" between our model $q_\\theta(\\mathbf{s})$ and the physical distribution $P_B(\\mathbf{s})$ is measured by the **Kullback-Leibler (KL) Divergence**. Minimizing the KL divergence is mathematically equivalent to minimizing the **Variational Free Energy** $F_q$:\n",
    "\n",
    "$$F_q = \\langle E \\rangle_{q_\\theta} - T \\cdot S[q_\\theta]$$\n",
    "\n",
    "* **$\\langle E \\rangle_{q_\\theta}$**: The expected energy under our model.\n",
    "* **$S[q_\\theta]$**: The Shannon entropy of our model, which encourages exploration.\n",
    "* **Code Example**: In `vca_solver`, the variables `meanFreeEnergy` and `varFreeEnergy` track this quantity as the model trains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14a74a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f1e9cc2",
   "metadata": {},
   "source": [
    "## 2.4 Variational Annealing Strategy\n",
    "In the provided code, we perform **Variational Annealing**:\n",
    "1.  Start at a high temperature $T_0$ where the free energy is easy to minimize.\n",
    "2.  Gradually decrease $T$ (and the transverse field $B_x$) according to an annealing schedule.\n",
    "3.  At each step, update the RNN parameters $\\theta$ to track the shifting Boltzmann distribution.\n",
    "4.  By the time $T \\to 0$, $q_\\theta(\\mathbf{s})$ should ideally collapse onto the global energy minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd388b8",
   "metadata": {},
   "source": [
    "# Section 3: Variational Neural Annealing (VNA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27048450",
   "metadata": {},
   "source": [
    "## 3.1 The Variational Policy: $q_\\theta(\\mathbf{s})$\n",
    "In VNA, the probability distribution over spin configurations is represented by a Neural Network (the **Dilated RNN** in your code). \n",
    "\n",
    "### Autoregressive Property\n",
    "The mathematical essence of using an RNN is its **autoregressive** nature. The joint probability of a configuration $\\mathbf{s} = (s_1, s_2, \\dots, s_N)$ is decomposed into a product of conditional probabilities:\n",
    "$$q_\\theta(\\mathbf{s}) = \\prod_{i=1}^N q_\\theta(s_i | s_{<i})$$\n",
    "\n",
    "* **Sampling**: The code implements this in the `sample` method. It generates $s_1$, then feeds $s_1$ back into the RNN to generate $s_2$, and so on.\n",
    "* **Normalization**: Unlike traditional physics methods, this product is **guaranteed to be normalized** ($\\sum q_\\theta(\\mathbf{s}) = 1$), which bypasses the need to calculate the intractable partition function $Z$.\n",
    "\n",
    "### Dilated Structure\n",
    "The model uses a **Dilated RNN** where connections skip certain steps (defined by `n - 2**i`). This allows the model to capture long-range correlations between spins that are far apart in the sequence but physically coupled in the Hamiltonian."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43738c9",
   "metadata": {},
   "source": [
    "## 3.2 The Objective Function\n",
    "The goal is to minimize the **Variational Free Energy**:\n",
    "$$F_q(\\theta) = \\mathbb{E}_{\\mathbf{s} \\sim q_\\theta} [E(\\mathbf{s}) + T \\ln q_\\theta(\\mathbf{s})]$$\n",
    "\n",
    "### The Gradient Challenge\n",
    "Since the spin configurations $\\mathbf{s}$ are discrete (0 or 1), we cannot propagate gradients directly through the samples. To solve this, we use the **Policy Gradient (REINFORCE)** theorem from Reinforcement Learning.\n",
    "\n",
    "The gradient of the Free Energy with respect to the network parameters $\\theta$ is:\n",
    "$$\\nabla_\\theta F_q \\approx \\mathbb{E}_{\\mathbf{s} \\sim q_\\theta} \\left[ \\nabla_\\theta \\ln q_\\theta(\\mathbf{s}) \\cdot \\left( F_{loc}(\\mathbf{s}) - \\bar{F} \\right) \\right]$$\n",
    "\n",
    "Where:\n",
    "* **$F_{loc}(\\mathbf{s}) = E(\\mathbf{s}) + T \\ln q_\\theta(\\mathbf{s})$** is the \"local\" free energy of a sample.\n",
    "* **$\\bar{F}$** is the average free energy of the batch, acting as a baseline to reduce variance.\n",
    "\n",
    "### Code Implementation: The \"Fake\" Cost Function\n",
    "In your `vca_solver`, this is implemented using a \"stop gradient\" trick to force TensorFlow to compute the correct policy gradient:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7807f602",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Eloc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3312/202901050.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# From vca_solver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mFloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEloc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mT_placeholder\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlog_probs_forgrad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmultiply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs_forgrad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m        \u001b[0;34m-\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_probs_forgrad\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Eloc' is not defined"
     ]
    }
   ],
   "source": [
    "# From vca_solver\n",
    "Floc = Eloc + T_placeholder * log_probs_forgrad\n",
    "cost = tf.reduce_mean(tf.multiply(log_probs_forgrad, tf.stop_gradient(Floc))) \\\n",
    "       - tf.reduce_mean(log_probs_forgrad) * tf.reduce_mean(tf.stop_gradient(Floc))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d51409",
   "metadata": {},
   "source": [
    "# Section 4: Algorithmic Implementation in Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "897872cf",
   "metadata": {},
   "source": [
    "## 4.1 Adapting from Command Line to Notebook\n",
    "In a standard environment, you would run the solver via the command line:\n",
    "`python vca.py ../../dataset/EA/EA_10x10/10x10_uniform_seed1.txt`\n",
    "\n",
    "In this Notebook, we instantiate the `config` class directly with the path to your problem instance file. This allows us to inspect variables and visualize progress in real-time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bd86358",
   "metadata": {},
   "source": [
    "## 4.2 The Sampling and Evaluation Loop\n",
    "The core of the implementation involves three main stages that repeat during the annealing process:\n",
    "\n",
    "1. **Sampling**: The RNN generates a batch of spin configurations $\\mathbf{s}$ using the `sample` method. \n",
    "2. **Energy Evaluation**:\n",
    "    * **Diagonal Elements**: Calculated using `Fullyconnected_diagonal_matrixelements` to get the classical Ising energy.\n",
    "    * **Local Energies**: The `Fullyconnected_localenergies` function computes the off-diagonal contributions from the transverse field $B_x$. This involves flipping spins and re-evaluating probabilities.\n",
    "3. **Gradient Update**: The `optstep` is executed using the \"Fake Cost\" derived in Section 3, updating the RNN parameters to favor lower free energy."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "191dcfe9",
   "metadata": {},
   "source": [
    "## 4.3 Execution Cell\n",
    "To run the solver in this Notebook, use the following code block. Ensure you have the problem instance file (e.g., `10x10_uniform_seed1.txt`) in your working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6e8f749",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../dataset/EA/EA_10x10/10x10_uniform_seed1.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_3312/1895977360.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# 2. Initialize configuration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mvca_config\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minstance_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# 3. Run the solver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/linle/Dropbox/Ising/RL4Ising/src/tutorials/VCA/config.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph_path, seed)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mN\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mJz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/c/Users/linle/Dropbox/Ising/RL4Ising/src/tutorials/VCA/config.py\u001b[0m in \u001b[0;36mread_graph\u001b[0;34m(self, graph_path)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgraph_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"r\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mis_first_line\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../dataset/EA/EA_10x10/10x10_uniform_seed1.txt'"
     ]
    }
   ],
   "source": [
    "# 1. Path to your problem instance\n",
    "instance_path = \"../../dataset/EA/EA_10x10/10x10_uniform_seed1.txt\" \n",
    "seed = 0\n",
    "\n",
    "# 2. Initialize configuration\n",
    "vca_config = config(instance_path, seed)\n",
    "\n",
    "# 3. Run the solver\n",
    "# This will output the annealing progress, energy (E), and free energy (F)\n",
    "mean_energies, min_energies = vca_solver(vca_config)\n",
    "\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"Minimum Energy Found: {min_energies}\")\n",
    "print(f\"Mean Energy: {mean_energies}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vca",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
